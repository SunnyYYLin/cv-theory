{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet复现实验\n",
    "\n",
    "## 实验目的\n",
    "试选用一个深度学习框架，利用MNIST数据集训练一个LeNet模型，并统计平均识别准确率\n",
    "\n",
    "## 实验环境\n",
    "PyTorch 2.4.0\n",
    "CUDA 12.4\n",
    "\n",
    "## 实验方法\n",
    "\n",
    "### 选择深度学习框架\n",
    "选择PyTorch作为本次实验的深度学习框架，主要是因为它提供了动态计算图的支持，这使得代码调试更加直观且易于理解。PyTorch拥有强大的社区支持和丰富的资源，这对于解决开发过程中遇到的问题非常有帮助。此外，PyTorch与CUDA的集成非常紧密，能够充分利用GPU加速计算，这对于拥有如3060 Laptop GPU这样支持CUDA操作的显卡的设备来说，意味着可以显著提升训练速度和效率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST数据集\n",
    "MNIST 数据集是一个非常著名的手写数字识别数据集，它常被用来作为机器学习和计算机视觉领域中的基准测试数据。MNIST（Modified National Institute of Standards and Technology）数据集包含60000个训练样本和10000个测试样本，每个样本都是一个28x28像素大小的灰度图像，代表了0到9之间的某个数字。`torchvision`的`datasets`内置了加载MNIST的功能，可以用`datasets.MNIST`下载、加载和预处理。在预处理中，用`transforms`将其归一化到0-1之间，并转换为张量。\n",
    "\n",
    "数据集应该被划分为训练集、验证集、测试集三个部分。其中测试集仅用于测试模型性能，不应该参与训练，就用MNIST提供的测试集；训练集用于模型训练；验证集用于在训练时验证模型效果，调整超参，可以从MNIST训练集中抽取一部分，这里用`torch.utils.data`中的`random_split`函数分割，比例选取为8:2。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Pre-processing\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Load MNIST dataset\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Split train dataset into train and validation\n",
    "train_ratio = 0.8\n",
    "train_size = int(train_ratio * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "# Create dataloaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LeNet\n",
    "LeNet 是一个经典的卷积神经网络，其中LeNet-5由Yann LeCun等人在1998年的论文《Gradient-Based Learning Applied to Document Recognition》中提出。这个网络架构主要用于手写字符识别，特别是在识别邮政编码和银行支票上的数字方面取得了成功。根据LeNet-5的原始论文，其结构如下所述。\n",
    "\n",
    "#### C1\n",
    "第一层（C1）是一个包含6个5x5卷积核的卷积层，用以提取图像中的基本特征。输入层接收的是32x32像素的图像。这意味着C1的padding=2：\n",
    "\n",
    "#### S2\n",
    "第二层(S2)原文是：\n",
    "```\n",
    "The four inputs to a unit in S2 are added, then multiplied by a trainable coefficient, and then added to a trainable bias. The result is passed through a sigmoidal function.\n",
    "```\n",
    "这相当于先经过2x2的平均池化层，然后通过一层激活函数：\n",
    "$$y^{(2)}=\\sigma(wa^{(2)}+b)$$\n",
    "\n",
    "#### C3\n",
    "第三层（C3）是一个包含16个5x5卷积核的卷积层。值得注意的是每个卷积核与S2的6个特征图特征图并非都是全部连接的。具体来说：\n",
    "- 前六个C3特征图从S2层的每三个连续特征图中获取输入。\n",
    "- 接下来的六个C3特征图从S2层的每四个连续特征图中获取输入。\n",
    "- 再接下来的三个C3特征图从S2层的一些不连续的四个特征图中获取输入。\n",
    "- 最后一个C3特征图从所有的S2特征图中获取输入。\n",
    "卷积核对每个相连的特征图分通道卷积，然后将所有通道按元素相加，最终输出16个10x10的特征图。\n",
    "\n",
    "这需要我们定义新的神经网络层继承自`nn.Module`："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNetC3(nn.Module):\n",
    "    def __init__(self, num_s2_feature_maps=6, out_channels=16, kernel_size=(5, 5), stride=1, padding=0):\n",
    "        super(LeNetC3, self).__init__()\n",
    "\n",
    "        self.connections = [\n",
    "                [(i + j) % num_s2_feature_maps for j in range(3)] for i in range(num_s2_feature_maps) # 0-5\n",
    "            ] + [\n",
    "                [(i + j) % num_s2_feature_maps for j in range(4)] for i in range(num_s2_feature_maps) # 6-11\n",
    "            ] + [\n",
    "                [0, 1, 3, 4], [1, 2, 4, 5], [0, 2, 3, 5] # 12-14\n",
    "            ] + [\n",
    "                list(range(num_s2_feature_maps)) # 15\n",
    "            ]\n",
    "        \n",
    "        self.conv_layers = nn.ModuleList()\n",
    "        for i in range(out_channels):\n",
    "            conv = nn.Conv2d(len(self.connections[i]), 1, kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "            self.conv_layers.append(conv)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = []\n",
    "        for i, conv in enumerate(self.conv_layers):\n",
    "            indices = self.connections[i]\n",
    "            conv_input = x[:, indices, :, :]\n",
    "            conv_output = conv(conv_input)\n",
    "            outputs.append(conv_output)\n",
    "        return torch.cat(outputs, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### S4\n",
    "第四层（S4）再次执行与S2相似的子采样，等价于2x2的平均池化层再通过激活函数层，进一步压缩空间信息，输出16个5x5特征图。\n",
    "\n",
    "#### C5\n",
    "第五层（C5）是一个包含120个5x5卷积核的卷积层，每个卷积核和S4的16个特征图全有连接，输出120个1x1特征图，相当于一个120维向量。\n",
    "\n",
    "#### F6\n",
    "第六层（F6）是一个宽度84的全连接层，其激活函数为：\n",
    "$$f(a)=A\\tanh(Sa)$$\n",
    "其中作者取$A=1.7159, S=0.6667$以满足$f(1)=1,f(-1)=-1$\n",
    "\n",
    "#### OUTPUT\n",
    "输出层（OUTPUT）是一个宽度10的径向激活函数（RBF）全连接层：\n",
    "$$\\phi_i(y^{(6)})=\\exp(-\\frac{\\sum_{j}\\|y_j^{(6)}-w_{ij}\\|^2}{\\sigma_i^2})$$\n",
    "我们参考[torchrbf](https://github.com/ArmanMaesumi/torchrbf)中的RBF层："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBF(nn.Module):\n",
    "    \"\"\"\n",
    "    Transforms incoming data using a given radial basis function:\n",
    "    u_{i} = rbf(||x - c_{i}|| / s_{i})\n",
    "\n",
    "    Arguments:\n",
    "        in_features: size of each input sample\n",
    "        out_features: size of each output sample\n",
    "\n",
    "    Shape:\n",
    "        - Input: (N, in_features) where N is an arbitrary batch size\n",
    "        - Output: (N, out_features) where N is an arbitrary batch size\n",
    "\n",
    "    Attributes:\n",
    "        centres: the learnable centres of shape (out_features, in_features).\n",
    "            The values are initialised from a standard normal distribution.\n",
    "            Normalising inputs to have mean 0 and standard deviation 1 is\n",
    "            recommended.\n",
    "        \n",
    "        log_sigmas: logarithm of the learnable scaling factors of shape (out_features).\n",
    "        \n",
    "        basis_func: the radial basis function used to transform the scaled\n",
    "            distances.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_features, out_features, basis_func):\n",
    "        super(RBF, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.centres = nn.Parameter(torch.Tensor(out_features, in_features))\n",
    "        self.log_sigmas = nn.Parameter(torch.Tensor(out_features))\n",
    "        self.basis_func = basis_func\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.normal_(self.centres, 0, 1)\n",
    "        nn.init.constant_(self.log_sigmas, 0)\n",
    "\n",
    "    def forward(self, input):\n",
    "        size = (input.size(0), self.out_features, self.in_features)\n",
    "        x = input.unsqueeze(1).expand(size)\n",
    "        c = self.centres.unsqueeze(0).expand(size)\n",
    "        distances = (x - c).pow(2).sum(-1).pow(0.5) / torch.exp(self.log_sigmas).unsqueeze(0)\n",
    "        return self.basis_func(distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "综上，LeNet的结构可以表示为："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        # C1 Convolution Layer\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5, padding=2)  # Input channels=1 for grayscale, output channels=6, kernel size=5x5\n",
    "        # S2 Subsampling Layer (Pooling)\n",
    "        self.pool = nn.AvgPool2d(2, 2)  # 2x2 average pooling\n",
    "        self.w1 = nn.Parameter(torch.randn(1, 6, 1, 1))\n",
    "        self.b1 = nn.Parameter(torch.randn(1, 6, 1, 1))\n",
    "        # C3 Convolution Layer with custom connections\n",
    "        self.conv2 = LeNetC3(num_s2_feature_maps=6, out_channels=16, kernel_size=(5, 5))\n",
    "        # S4 Subsampling Layer\n",
    "        self.pool = nn.AvgPool2d(2, 2)\n",
    "        self.w2 = nn.Parameter(torch.randn(1, 16, 1, 1))\n",
    "        self.b2 = nn.Parameter(torch.randn(1, 16, 1, 1))\n",
    "        # C5 Convolution Layer\n",
    "        self.conv3 = nn.Conv2d(16, 120, 5)  # Input channels=16 from S4, output channels=120, kernel size=5x5\n",
    "        # F6 Fully Connected Layer\n",
    "        self.fc1 = nn.Linear(120, 84)\n",
    "        self.A = 1.7159\n",
    "        self.S = 2/3\n",
    "        # Output Layer\n",
    "        self.fc2 = RBF(84, 10, lambda x: torch.exp(-x**2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.w1 * x + self.b1\n",
    "        x = F.sigmoid(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.w2 * x + self.b2\n",
    "        x = F.sigmoid(x)\n",
    "        x = self.conv3(x)\n",
    "        x = x.view(-1, 120)  # Flatten the tensor for the fully connected layer\n",
    "        x = self.fc1(x)\n",
    "        x = self.A * F.tanh(self.S * x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 2.303\n",
      "[1,   200] loss: 2.303\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[1;32m     26\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m---> 27\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Print statistics\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/cv/lib/python3.12/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/cv/lib/python3.12/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/cv/lib/python3.12/site-packages/torch/autograd/graph.py:769\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    770\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define the device to use\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Instantiate the model\n",
    "model = LeNet().to(device)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# Initialize TensorBoard writer\n",
    "writer = SummaryWriter(log_dir='logs')\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10  # Number of epochs to train the model\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:  # print every 100 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 100:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "    # Log the scalar values to TensorBoard\n",
    "    writer.add_scalar('Training Loss', loss.item(), epoch)\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "# Close the writer\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
