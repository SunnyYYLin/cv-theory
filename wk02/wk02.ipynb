{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet复现实验\n",
    "\n",
    "## 实验目的\n",
    "试选用一个深度学习框架，利用MNIST数据集训练一个LeNet模型，并统计平均识别准确率\n",
    "\n",
    "## 实验环境\n",
    "PyTorch 2.4.0\n",
    "CUDA 12.4\n",
    "\n",
    "## 实验方法\n",
    "\n",
    "### 选择深度学习框架\n",
    "选择PyTorch作为本次实验的深度学习框架，主要是因为它提供了动态计算图的支持，这使得代码调试更加直观且易于理解。PyTorch拥有强大的社区支持和丰富的资源，这对于解决开发过程中遇到的问题非常有帮助。此外，PyTorch与CUDA的集成非常紧密，能够充分利用GPU加速计算，这对于拥有如3060 Laptop GPU这样支持CUDA操作的显卡的设备来说，意味着可以显著提升训练速度和效率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import math\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST数据集\n",
    "MNIST 数据集是一个非常著名的手写数字识别数据集，它常被用来作为机器学习和计算机视觉领域中的基准测试数据。MNIST（Modified National Institute of Standards and Technology）数据集包含60000个训练样本和10000个测试样本，每个样本都是一个28x28像素大小的灰度图像，代表了0到9之间的某个数字。`torchvision`的`datasets`内置了加载MNIST的功能，可以用`datasets.MNIST`下载、加载和预处理。在预处理中，用`transforms`将其归一化到0-1之间，并转换为张量。\n",
    "\n",
    "数据集应该被划分为训练集、验证集、测试集三个部分。其中测试集仅用于测试模型性能，不应该参与训练，就用MNIST提供的测试集；训练集用于模型训练；验证集用于在训练时验证模型效果，调整超参，可以从MNIST训练集中抽取一部分，这里用`torch.utils.data`中的`random_split`函数分割，比例选取为8:2。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Pre-processing\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.05,), (0.5,))\n",
    "])\n",
    "\n",
    "# Load MNIST dataset\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Split train dataset into train and validation\n",
    "train_ratio = 0.8\n",
    "train_size = int(train_ratio * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "# Create dataloaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LeNet\n",
    "LeNet 是一个经典的卷积神经网络，其中LeNet-5由Yann LeCun等人在1998年的论文《Gradient-Based Learning Applied to Document Recognition》中提出。这个网络架构主要用于手写字符识别，特别是在识别邮政编码和银行支票上的数字方面取得了成功。根据LeNet-5的原始论文，其结构如下所述。\n",
    "\n",
    "#### C1\n",
    "第一层（C1）是一个包含6个5x5卷积核的卷积层，用以提取图像中的基本特征。输入层接收的是32x32像素的图像。这意味着C1的padding=2：\n",
    "\n",
    "#### S2\n",
    "第二层(S2)原文是：\n",
    "```\n",
    "The four inputs to a unit in S2 are added, then multiplied by a trainable coefficient, and then added to a trainable bias. The result is passed through a sigmoidal function.\n",
    "```\n",
    "这相当于先经过2x2的平均池化层，然后通过一层激活函数：\n",
    "$$y^{(2)}=\\sigma(wa^{(2)}+b)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNetSampling(nn.Module):\n",
    "    def __init__(self, out_channels, kernel_size):\n",
    "        super(LeNetSampling, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.weights = nn.Parameter(torch.Tensor(1, out_channels, 1, 1))\n",
    "        self.bias = nn.Parameter(torch.Tensor(1, out_channels, 1, 1))\n",
    "        self.reset_parameters()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.avg_pool2d(x, self.kernel_size)\n",
    "        x = x*self.weights + self.bias\n",
    "        return x\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        self.weights = nn.init.kaiming_uniform_(self.weights, a=math.sqrt(1))\n",
    "        self.bias.data.fill_(0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C3\n",
    "第三层（C3）是一个包含16个5x5卷积核的卷积层。值得注意的是每个卷积核与S2的6个特征图特征图并非都是全部连接的。具体来说：\n",
    "- 前六个C3特征图从S2层的每三个连续特征图中获取输入。\n",
    "- 接下来的六个C3特征图从S2层的每四个连续特征图中获取输入。\n",
    "- 再接下来的三个C3特征图从S2层的一些不连续的四个特征图中获取输入。\n",
    "- 最后一个C3特征图从所有的S2特征图中获取输入。\n",
    "卷积核对每个相连的特征图分通道卷积，然后将所有通道按元素相加，最终输出16个10x10的特征图。\n",
    "\n",
    "这需要我们定义新的神经网络层继承自`nn.Module`："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNetC3(nn.Module):\n",
    "    def __init__(self, num_s2_feature_maps=6, out_channels=16, kernel_size=(5, 5), stride=1, padding=0):\n",
    "        super(LeNetC3, self).__init__()\n",
    "\n",
    "        self.connections = [\n",
    "                [(i + j) % num_s2_feature_maps for j in range(3)] for i in range(num_s2_feature_maps) # 0-5\n",
    "            ] + [\n",
    "                [(i + j) % num_s2_feature_maps for j in range(4)] for i in range(num_s2_feature_maps) # 6-11\n",
    "            ] + [\n",
    "                [0, 1, 3, 4], [1, 2, 4, 5], [0, 2, 3, 5] # 12-14\n",
    "            ] + [\n",
    "                list(range(num_s2_feature_maps)) # 15\n",
    "            ]\n",
    "        \n",
    "        self.conv_layers = nn.ModuleList()\n",
    "        for i in range(out_channels):\n",
    "            conv = nn.Conv2d(len(self.connections[i]), 1, kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "            self.conv_layers.append(conv)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = []\n",
    "        for i, conv in enumerate(self.conv_layers):\n",
    "            indices = self.connections[i]\n",
    "            conv_input = x[:, indices, :, :]\n",
    "            conv_output = conv(conv_input)\n",
    "            outputs.append(conv_output)\n",
    "        return torch.cat(outputs, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### S4\n",
    "第四层（S4）再次执行与S2相似的子采样，等价于2x2的平均池化层再通过激活函数层，进一步压缩空间信息，输出16个5x5特征图。\n",
    "\n",
    "#### C5\n",
    "第五层（C5）是一个包含120个5x5卷积核的卷积层，每个卷积核和S4的16个特征图全有连接，输出120个1x1特征图，相当于一个120维向量。\n",
    "\n",
    "#### F6\n",
    "第六层（F6）是一个宽度84的全连接层，其激活函数为：\n",
    "$$f(a)=A\\tanh(Sa)$$\n",
    "其中作者取$A=1.7159, S=0.6667$以满足$f(1)=1,f(-1)=-1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tanh(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return 1.7159*torch.tanh(x*2/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OUTPUT\n",
    "输出层（OUTPUT）是一个宽度10的径向激活函数（RBF）全连接层：\n",
    "$$\\phi_i(y^{(6)})=\\exp(-\\frac{\\sum_{j}\\|y_j^{(6)}-w_{ij}\\|^2}{\\sigma_i^2})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBF(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(RBF, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.load_params()\n",
    "\n",
    "    def forward(self, x):\n",
    "        size = (x.size(0), self.out_channels, self.in_channels)\n",
    "        x = x.unsqueeze(1).expand(size)\n",
    "        c = self.kernels.unsqueeze(0).expand(size)\n",
    "        output = (x - c).pow(2).sum(-1)\n",
    "        return output\n",
    "     \n",
    "    def load_params(self):\n",
    "        kernels = []\n",
    "        for i in range(self.out_channels):\n",
    "            file = './RBF/' + str(i) + '_RBF.jpg'\n",
    "            image = Image.open(file).convert('L')\n",
    "            image = transform(image)\n",
    "            image = torch.where(image > 0.5, torch.tensor(1.0), torch.tensor(-1.0))\n",
    "            kernels.append(image)\n",
    "        self.kernels = torch.Tensor(kernels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "综上，LeNet的结构可以表示为："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        # C1 Convolution Layer\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5, padding=2)  # Input channels=1 for grayscale, output channels=6, kernel size=5x5\n",
    "        # S2 Subsampling Layer (Pooling)\n",
    "        self.sample1 = LeNetSampling(out_channels=6, kernel_size=(2, 2))\n",
    "        # C3 Convolution Layer with custom connections\n",
    "        self.conv2 = LeNetC3(num_s2_feature_maps=6, out_channels=16, kernel_size=(5, 5))\n",
    "        # S4 Subsampling Layer\n",
    "        self.sample2 = LeNetSampling(out_channels=16, kernel_size=(2, 2))\n",
    "        # C5 Convolution Layer\n",
    "        self.conv3 = nn.Conv2d(16, 120, 5)  # Input channels=16 from S4, output channels=120, kernel size=5x5\n",
    "        # F6 Fully Connected Layer\n",
    "        self.fc1 = nn.Linear(120, 84)\n",
    "        self.A = 1.7159\n",
    "        self.S = 2/3\n",
    "        # Output Layer\n",
    "        self.rbf = RBF(84, 10)\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.sample1(x)\n",
    "        x = F.tanh(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.sample2(x)\n",
    "        x = F.tanh(x)\n",
    "        x = self.conv3(x)\n",
    "        x = F.tanh(x)\n",
    "        x = x.view(-1, 120)  # Flatten the tensor for the fully connected layer\n",
    "        x = self.fc1(x)\n",
    "        x = self.A * F.tanh(self.S * x)\n",
    "        x = self.rbf(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/sunnylin/homework/cv-theory/wk02/RBF/0_RBF.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Instantiate the model\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mLeNet\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Loss function and optimizer\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss_fn\u001b[39m(output, target):\n",
      "Cell \u001b[0;32mIn[77], line 19\u001b[0m, in \u001b[0;36mLeNet.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m3\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Output Layer\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrbf \u001b[38;5;241m=\u001b[39m \u001b[43mRBF\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m84\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[76], line 6\u001b[0m, in \u001b[0;36mRBF.__init__\u001b[0;34m(self, in_channels, out_channels)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_channels \u001b[38;5;241m=\u001b[39m in_channels\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_channels \u001b[38;5;241m=\u001b[39m out_channels\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[76], line 19\u001b[0m, in \u001b[0;36mRBF.load_params\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_channels):\n\u001b[1;32m     18\u001b[0m     file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./RBF/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_RBF.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 19\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     20\u001b[0m     image \u001b[38;5;241m=\u001b[39m transform(image)\n\u001b[1;32m     21\u001b[0m     image \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mwhere(image \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m, torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m1.0\u001b[39m), torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1.0\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/envs/cv/lib/python3.12/site-packages/PIL/Image.py:3431\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3428\u001b[0m     filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mrealpath(os\u001b[38;5;241m.\u001b[39mfspath(fp))\n\u001b[1;32m   3430\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[0;32m-> 3431\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3432\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   3433\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/sunnylin/homework/cv-theory/wk02/RBF/0_RBF.jpg'"
     ]
    }
   ],
   "source": [
    "# Define the device to use\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Instantiate the model\n",
    "model = LeNet().to(device)\n",
    "\n",
    "# Loss function and optimizer\n",
    "def loss_fn(output, target):\n",
    "    loss = output[target==1].pow(2).sum()\n",
    "    loss += torch.log(torch.exp(torch.tensor(0.1))+torch.exp(-output[target==0]).sum())\n",
    "    return loss\n",
    "criterion = loss_fn\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "# Initialize TensorBoard writer\n",
    "writer = SummaryWriter(log_dir='logs')\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 20  # Number of epochs to train the model\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        running_loss += loss.item()\n",
    "        writer.add_scalar('Training Loss', loss.item(), epoch * len(train_loader) + i)\n",
    "        if i % 100 == 99:  # print every 100 mini-batches\n",
    "            print(f'Epoch{epoch}-batch{i+1}, loss: {running_loss / 100:.6f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "# Close the writer\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 28.80%\n",
      "Average Test Loss: 2.0777\n"
     ]
    }
   ],
   "source": [
    "# 切换到评估模式\n",
    "model.eval()\n",
    "\n",
    "# 初始化统计变量\n",
    "correct = 0\n",
    "total = 0\n",
    "test_loss = 0.0\n",
    "\n",
    "# 关闭梯度计算\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # 进行前向传播\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # 计算损失\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        # 获取预测类别\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        # 统计正确的预测数量\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# 计算准确率\n",
    "accuracy = 100 * correct / total\n",
    "avg_loss = test_loss / len(test_loader)\n",
    "\n",
    "print(f'Test Accuracy: {accuracy:.2f}%')\n",
    "print(f'Average Test Loss: {avg_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 修改后的LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyLeNet, self).__init__()\n",
    "        # C1 Convolution Layer\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5, padding=2)  # Input channels=1 for grayscale, output channels=6, kernel size=5x5\n",
    "        # S2 Subsampling Layer (Pooling)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)  # 2x2 average pooling\n",
    "        # C3 Convolution Layer\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)  # Input channels=6 from C1, output channels=16, kernel size=5x5\n",
    "        # S4 Subsampling Layer\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        # C5 Convolution Layer\n",
    "        self.conv3 = nn.Conv2d(16, 120, 5)  # Input channels=16 from S4, output channels=120, kernel size=5x5\n",
    "        # F6 Fully Connected Layer\n",
    "        self.fc1 = nn.Linear(120, 84)\n",
    "        self.fc2 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = x.view(-1, 120)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练修改后的LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch0-batch100, loss: 1.104\n",
      "Epoch0-batch200, loss: 0.337\n",
      "Epoch0-batch300, loss: 0.231\n",
      "Epoch0-batch400, loss: 0.163\n",
      "Epoch0-batch500, loss: 0.128\n",
      "Epoch0-batch600, loss: 0.124\n",
      "Epoch0-batch700, loss: 0.107\n",
      "Epoch1-batch100, loss: 0.101\n",
      "Epoch1-batch200, loss: 0.086\n",
      "Epoch1-batch300, loss: 0.100\n",
      "Epoch1-batch400, loss: 0.074\n",
      "Epoch1-batch500, loss: 0.071\n",
      "Epoch1-batch600, loss: 0.065\n",
      "Epoch1-batch700, loss: 0.078\n",
      "Epoch2-batch100, loss: 0.054\n",
      "Epoch2-batch200, loss: 0.057\n",
      "Epoch2-batch300, loss: 0.061\n",
      "Epoch2-batch400, loss: 0.055\n",
      "Epoch2-batch500, loss: 0.058\n",
      "Epoch2-batch600, loss: 0.053\n",
      "Epoch2-batch700, loss: 0.049\n",
      "Epoch3-batch100, loss: 0.047\n",
      "Epoch3-batch200, loss: 0.040\n",
      "Epoch3-batch300, loss: 0.044\n",
      "Epoch3-batch400, loss: 0.047\n",
      "Epoch3-batch500, loss: 0.039\n",
      "Epoch3-batch600, loss: 0.050\n",
      "Epoch3-batch700, loss: 0.041\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Define the device to use\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Instantiate the model\n",
    "model = MyLeNet().to(device)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# Initialize TensorBoard writer\n",
    "writer = SummaryWriter(log_dir='logs')\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 4  # Number of epochs to train the model\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        running_loss += loss.item()\n",
    "        writer.add_scalar('Training Loss', loss.item(), epoch * len(train_loader) + i)\n",
    "        if i % 100 == 99:  # print every 100 mini-batches\n",
    "            print(f'Epoch{epoch}-batch{i+1}, loss: {running_loss / 100:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "# Close the writer\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试模型性能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 98.53%\n",
      "Average Test Loss: 0.0420\n"
     ]
    }
   ],
   "source": [
    "# 切换到评估模式\n",
    "model.eval()\n",
    "\n",
    "# 初始化统计变量\n",
    "correct = 0\n",
    "total = 0\n",
    "test_loss = 0.0\n",
    "\n",
    "# 关闭梯度计算\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # 进行前向传播\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # 计算损失\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        # 获取预测类别\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        # 统计正确的预测数量\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# 计算准确率\n",
    "accuracy = 100 * correct / total\n",
    "avg_loss = test_loss / len(test_loader)\n",
    "\n",
    "print(f'Test Accuracy: {accuracy:.2f}%')\n",
    "print(f'Average Test Loss: {avg_loss:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
